
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>ReconFusion</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://jonbarron.info/zipnerf/img/nottingham.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://reconfusion.github.io/"/>
    <meta property="og:title" content="ReconFusion: 3D Reconstruction with Diffusion Priors" />
    <meta property="og:description" content="3D reconstruction methods such as Neural Radiance Fields (NeRFs) excel at rendering photorealistic novel views of complex scenes. However, recovering a high-quality NeRF typically requires tens to hundreds of input images, resulting in a time-consuming capture process. We present ReconFusion to reconstruct real-world scenes using only a few photos. Our approach leverages a diffusion prior for novel view synthesis, trained on synthetic and multiview datasets, which regularizes a NeRF-based 3D reconstruction pipeline at novel camera poses beyond those captured by the set of input images. Our method synthesizes realistic geometry and texture in underconstrained regions while preserving the appearance of observed regions. We perform an extensive evaluation across various real-world datasets, including forward-facing and 360-degree scenes, demonstrating significant performance improvements over previous few-view NeRF reconstruction approaches."/>

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="ReconFusion: 3D Reconstruction with Diffusion Priors" />
    <meta name="twitter:description" content="3D reconstruction methods such as Neural Radiance Fields (NeRFs) excel at rendering photorealistic novel views of complex scenes. However, recovering a high-quality NeRF typically requires tens to hundreds of input images, resulting in a time-consuming capture process. We present ReconFusion to reconstruct real-world scenes using only a few photos. Our approach leverages a diffusion prior for novel view synthesis, trained on synthetic and multiview datasets, which regularizes a NeRF-based 3D reconstruction pipeline at novel camera poses beyond those captured by the set of input images. Our method synthesizes realistic geometry and texture in underconstrained regions while preserving the appearance of observed regions. We perform an extensive evaluation across various real-world datasets, including forward-facing and 360-degree scenes, demonstrating significant performance improvements over previous few-view NeRF reconstruction approaches."/>
    <meta name="twitter:image" content="https://jonbarron.info/zipnerf/img/teaser.jpg" />


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>âš¡</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js"></script>

    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>

    <script>
        function selectCompVideo() {
          var scene = document.getElementById("scene_btn").value;
          var method = document.getElementById("method_btn").value;
          var video = document.getElementById("compVideo");
          video.src = "videos/" + scene + "_" + method + "_vs_ours.mp4";
        }
    </script>

<style>
    .thumbnail-img {
        max-width: 100%;
        height: auto;
        width: auto\9; /* IE8 */
    }

    .pill {
        cursor: pointer;
        padding: 5px;
        margin: 5px;
        border: 1px solid #ddd;
        border-radius: 5px;
        display: inline-block;
        transition: background-color 0.3s;
    }

    .active-pill {
        background-color: #e0e0e0; /* Adjust the color as needed */
    }
</style>


<script>
    // JavaScript to handle mouseover and mouseout events
    var activeMethodPill = null;
    var activeScenePill = null;

    function selectCompVideo(method, scene, methodPill, scenePill) {
        // Your existing logic for video selection
        var video = document.getElementById("compVideo");
        video.src = "videos/" + scene + "_" + method + "_vs_ours.mp4";

        // Handling the active method pill
        if (activeMethodPill) {
            activeMethodPill.classList.remove("active-pill");
        }
        if (methodPill) {
            methodPill.classList.add("active-pill");
            activeMethodPill = methodPill;
        }

        // Handling the active scene pill
        if (activeScenePill) {
            activeScenePill.classList.remove("active-pill");
        }
        if (scenePill) {
            scenePill.classList.add("active-pill");
            activeScenePill = scenePill;
        }
    }
</script>

</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>ReconFusion</b>: 3D Reconstruction with Diffusion Priors</br> 
            </h2>
        </div>
        <div class="row">
            <div class="col-md-14 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://www.cs.columbia.edu/~rundi/">
                            Rundi Wu
                        </a><sup>1</sup>*
                    </li>
                    <li>
                        <a href="http://bmild.github.io/">
                            Ben Mildenhall
                        </a><sup>2</sup>*
                    </li>
                    <li>
                        <a href="https://henzler.github.io/">
                            Philipp Henzler
                        </a><sup>2</sup>
                    </li>
                    <li>
                        <a href="https://keunhong.com/">
                            Keunhong Park
                        </a><sup>2</sup>
                    </li>
                    <br>
                    <li>
                        <a href="https://ruiqigao.github.io/">
                            Ruiqi Gao
                        </a><sup>2</sup>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=_pKKv2QAAAAJ&hl=en/">
                            Daniel Watson
                        </a><sup>2</sup>
                    </li>
                    <li>
                        <a href="https://pratulsrinivasan.github.io/">
                            Pratul P. Srinivasan
                        </a><sup>2</sup>
                    </li>
                    <li>
                        <a href="https://dorverbin.github.io/">
                            Dor Verbin
                        </a><sup>2</sup>
                    </li>
                    <br>
                    <li>
                        <a href="https://jonbarron.info/">
                            Jonathan T. Barron
                        </a><sup>2</sup>
                    </li>
                    <li>
                        <a href="https://poolio.github.io/">
                            Ben Poole
                        </a><sup>2</sup>
                    </li>
                    <li>
                        <a href="https://holynski.org/">
                            Aleksander Holynski
                        </a><sup>2</sup>*
                    </li>
                    <!-- </br>Google -->
                </ul>
            </div>
            <div class="col-md-12 text-center">
                <sup>1</sup>Columbia University, &nbsp <sup>2</sup>Google Research
            </div>
            <div class="col-md-12 text-center">
                * Denotes equal contribution
            </div> </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/#">
                            <image src="img/#.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <!--<li>
                            <a href="https://www.youtube.com/">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>-->
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/#.mp4" type="video/mp4" />
                </video>
						</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    3D reconstruction methods such as Neural Radiance Fields (NeRFs) excel at rendering photorealistic novel views of complex scenes. However, recovering a high-quality NeRF typically requires tens to hundreds of input images, resulting in a time-consuming capture process. We present ReconFusion to reconstruct real-world scenes using only a few photos. Our approach leverages a diffusion prior for novel view synthesis, trained on synthetic and multiview datasets, which regularizes a NeRF-based 3D reconstruction pipeline at novel camera poses beyond those captured by the set of input images. Our method synthesizes realistic geometry and texture in underconstrained regions while preserving the appearance of observed regions. We perform an extensive evaluation across various real-world datasets, including forward-facing and 360-degree scenes, demonstrating significant performance improvements over previous few-view NeRF reconstruction approaches.
                </p>
            </div>
        </div>
        <br>


        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://youtube.com/embed/xrrhynRzC8k" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->
<!-- <br> -->
        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    360Â° Video Flythroughs
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/videoseries?list=PLzPoYEE6Aw7Jzjek1uEIPnpcTDL3u8tb4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                        <iframe src="https://youtube.com/embed/jbE2ri8xEZo" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->
<!-- <br> -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    ReconFusion
                </h3>
                <image src="img/overview_combined.png" width=100%></image>
                <p class="text-justify">
                    (a) We optimize a NeRF to minimize a reconstruction loss \(\mathcal{L}_\mathrm{recon}\) between renderings and a few input images, as well as a sample loss \(\mathcal{L}_\mathrm{sample}\) between a rendering from a random pose and an image predicted by a diffusion model for that pose. (b) To generate the sample image, we use a PixelNeRF-style model to fuse information from the input images and to render a predicted feature map corresponding to the sample view camera pose. (c) This feature map is concatenated with the noisy latent (computed from the current NeRF rendering at that pose) and is provided to a diffusion model, which additionally uses CLIP embeddings of the input images via cross-attention. The resulting decoded output sample is used to enforce an image-space loss on the corresponding NeRF rendering (\(\mathcal{L}_\mathrm{sample}\)).
                </p>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Comparisons
                </h3>

<!--                 <div class="text-center">
                    <label id="method_label">Baseline method:</label>
                    <select name="method" id="method_btn" onchange="selectCompVideo()">
                        <option value="zipnerf">Zip-NeRF</option>
                        <option value="diffusionerf">DiffusioNeRF</option>
                        <option value="freenerf">FreeNeRF</option>
                        <option value="simplenerf">SimpleNeRF</option>
                        <option value="zeronvs">ZeroNVS</option>
                    </select>
                    &emsp;

                    <label id="scene_label">Scene:</label>
                    <select name="scene" id="scene_btn" onchange="selectCompVideo()">
                        <option value="mipnerf360_bonsai">mip-NeRF 360/bonsai, 9 views</option>
                        <option value="mipnerf360_kitchen">mip-NeRF 360/kitchen, 9 views</option>
                        <option value="co3d_bench_185_19987_38634">CO3D/bench, 6 views</option>
                        <option value="co3d_plant_188_20319_36755">CO3D/plant, 6 views</option>
                        <option value="dtu_scan31">DTU/scan31, 3 views</option>
                        <option value="dtu_scan45">DTU/scan45, 3 views</option>
                        <option value="llff_fern">LLFF/fern, 3 views</option>
                        <option value="llff_horns">LLFF/horns, 3 views</option>
                        <option value="re10k_00beb03ef95dc637">Re10K/bedroom, 3 views</option>
                        <option value="re10k_000c3ab189999a83">Re10K/living room, 3 views</option>
                    </select>
                </div> -->

<div class="text-center">
    <div class="pill-row" id="method-pills">
   <span> Compare to: </span>
        <span class="pill method-pill" data-value="zipnerf" onclick="selectCompVideo('zipnerf', getSceneValue(), this, activeScenePill)">Zip-NeRF</span>
        <span class="pill method-pill" data-value="diffusionerf" onclick="selectCompVideo('diffusionerf', getSceneValue(), this, activeScenePill)">DiffusioNeRF</span>
        <span class="pill method-pill" data-value="freenerf" onclick="selectCompVideo('freenerf', getSceneValue(), this, activeScenePill)">FreeNeRF</span>
        <span class="pill method-pill" data-value="simplenerf" onclick="selectCompVideo('simplenerf', getSceneValue(), this, activeScenePill)">SimpleNeRF</span>
        <span class="pill method-pill" data-value="zeronvs" onclick="selectCompVideo('zeronvs', getSceneValue(), this, activeScenePill)">ZeroNVS</span>
    </div>
    <div class="pill-row" id="scene-pills">
        <span class="pill scene-pill" data-value="dtu_scan31" onclick="selectCompVideo(getMethodValue(), 'dtu_scan31', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/dtu_scan31_thumbnail.jpg" alt="DTU/scan31" width="64">
        </span>
        <span class="pill scene-pill" data-value="dtu_scan45" onclick="selectCompVideo(getMethodValue(), 'dtu_scan45', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/dtu_scan45_thumbnail.jpg" alt="DTU/scan45" width="64">
        </span>
        <span class="pill scene-pill" data-value="llff_fern" onclick="selectCompVideo(getMethodValue(), 'llff_fern', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/llff_fern_thumbnail.jpg" alt="LLFF/fern" width="64">
        </span>
        <span class="pill scene-pill" data-value="llff_horns" onclick="selectCompVideo(getMethodValue(), 'llff_horns', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/llff_horns_thumbnail.jpg" alt="LLFF/horns" width="64">
        </span>
        <span class="pill scene-pill" data-value="re10k_00beb03ef95dc637" onclick="selectCompVideo(getMethodValue(), 're10k_00beb03ef95dc637', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/re10k_00beb03ef95dc637_thumbnail.jpg" alt="Re10K/bedroom" width="64">
        </span>
    </div>
    <div class="pill-row" id="scene-pills">
        <span class="pill scene-pill" data-value="re10k_000c3ab189999a83" onclick="selectCompVideo(getMethodValue(), 're10k_000c3ab189999a83', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/re10k_000c3ab189999a83_thumbnail.jpg" alt="Re10K/living room" width="64">
        </span>
        <span class="pill scene-pill" data-value="co3d_bench_185_19987_38634" onclick="selectCompVideo(getMethodValue(), 'co3d_bench_185_19987_38634', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/co3d_bench_185_19987_38634_thumbnail.jpg" alt="CO3D/bench" width="64">
        </span>
        <span class="pill scene-pill" data-value="co3d_plant_188_20319_36755" onclick="selectCompVideo(getMethodValue(), 'co3d_plant_188_20319_36755', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/co3d_plant_188_20319_36755_thumbnail.jpg" alt="CO3D/plant" width="64">
        </span>
        <span class="pill scene-pill" data-value="mipnerf360_bonsai" onclick="selectCompVideo(getMethodValue(), 'mipnerf360_bonsai', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/mipnerf360_bonsai_thumbnail.jpg" alt="mip-NeRF 360/bonsai" width="64">
        </span>
        <span class="pill scene-pill" data-value="mipnerf360_kitchen" onclick="selectCompVideo(getMethodValue(), 'mipnerf360_kitchen', activeMethodPill, this)">
            <img class="thumbnail-img" src="thumbnails/mipnerf360_kitchen_thumbnail.jpg" alt="mip-NeRF 360/kitchen" width="64">
        </span>
    </div>
</div>
<input type="hidden" id="method_btn" value="zipnerf">
<input type="hidden" id="scene_btn" value="mipnerf360_bonsai">



<script>

    // Function to get the current method value
    function getMethodValue() {
        return document.getElementById('method_btn').value;
    }

    // Function to get the current scene value
    function getSceneValue() {
        return document.getElementById('scene_btn').value;
    }
// Attach event listeners to all elements with the class 'pill' after a slight delay
</script>


                
                <div class="text-center">
                    <video class="video" width=100% id="compVideo" loop playsinline autoplay muted onplay="resizeAndPlay(this)">
                        <source src="videos/mipnerf360_bonsai_zipnerf_vs_ours.mp4" />
                    </video>
                    <canvas height=0 class="videoMerge" id="compVideoMerge"></canvas>
                    <p class="text-justify" style="text-align: center;">
                        Baseline method (left) vs our ReconFusion (right).
                    </p>
                </div>
            </div>
        </div>
        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Samples from diffusion model
                </h3>
                <video id="v0" width="100%" autoplay loop muted>
                <source src="img/#.m4v" type="video/mp4" />
                </video>
                <p class="text-justify">
                    Compare ablations of our method. TBA. 
                </p>
            </div>
        </div>
        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Different amount of sparsity
                </h3>
                <p class="text-justify" style="color:red">
                    Hover over the plot to show rendered video under different number of views.
                </p>
                
                <!-- top down layout -->
                <canvas id="sparsityChart" style="max-height: 300px; max-width: 500px; margin: auto;"></canvas>
                <script src="js/sparsity_chart.js"></script>
    
                <div class="text-center">
                    <video class="video" width=100% id="sparsityVideo" loop playsinline autoplay muted onplay="playOnCanvas(this, 250)">
                        <source src="videos/sparsity/kitchenlego_3.mp4" type="video/mp4" />
                    </video>
                    <canvas height=0 class="videoWrapper" id="sparsityVideoWrapper"></canvas>
                    <div class="text-center">
                        Rendered video under <span id="sparsityValue" style="color: red;">3</span> views
                    </div>
                </div>
                
                <!-- left right layout -->
                <!-- <table style="width: 100%; border-collapse: collapse;">
                    <tr>
                      <td style="text-align: center;" >
                        <canvas id="sparsityChart" style="max-height: 250px; max-width: 200px; margin: auto;"></canvas>
                        <script src="js/sparsity_chart.js"></script>
                      </td>
                      <td style="text-align: center;">
                        <video class="video" width=100% id="sparsityVideo" loop playsinline autoplay muted onplay="playOnCanvas(this, 180)">
                            <source src="videos/sparsity/kitchenlego_3.mp4" type="video/mp4" />
                        </video>
                        <canvas height=0 class="videoWrapper" id="sparsityVideoWrapper"></canvas>
                      </td>
                    </tr>
                    <tr>
                      <td style="text-align: center;"></td>
                      <td style="text-align: center;">Rendered video under <span id="sparsityValue" style="color: red;">3</span> views</td>
                    </tr>
                </table> -->

                <p class="text-justify">
                    Our learned diffusion prior improves performance over the Zip-NeRF baseline up to as many as 81 input views on the kitchenlego scene from the mip-NeRF 360 dataset.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{wu2023reconfusion,
    title={ReconFusion: 3D Reconstruction with Diffusion Priors},
    author={Rundi Wu and Ben Mildenhall and Philipp Henzler and 
			Keunhong Park and Ruiqi Gao and Daniel Watson and 
			Pratul P. Srinivasan and Dor Verbin and Jonathan T. Barron 
			and Ben Poole and Aleksander Holynski},
    journal={arxiv},
    year={2023}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                Thanks to 
                    <br><br>
                The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a> and <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
